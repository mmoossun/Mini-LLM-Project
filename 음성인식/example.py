import streamlit as st
import whisper
import speech_recognition as sr
from langchain_openai import AzureChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("base")
file_name = "recorded_audio.wav"

# Recognizer ê°ì²´ ìƒì„±
r = sr.Recognizer()

def transcribe_audio(audio_file):
    # Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    audio_bytes = audio_file.read()
    with open(file_name, "wb") as f:
        f.write(audio_bytes)
    result = model.transcribe(file_name)
    return result['text']

def main():
    st.title("ğŸ—£ï¸ ìŒì„± íŒŒì¼ ê¸°ë°˜ ì±—ë´‡ ë° íšŒì˜ë¡ ì‘ì„±ê¸°")

    # ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    def get_audio_input(audio_file_path):
        with open(audio_file_path, "rb") as audio_file:
            text = transcribe_audio(audio_file)
        if text:
            return text
        else:
            return None

    # ì±—ë´‡ ì‘ë‹µì„ ì–»ëŠ” í•¨ìˆ˜
    def get_chatbot_response(user_input):
        return f"'{user_input}'"

    def record_audio():
        with sr.Microphone() as source:
            st.write("ğŸ”´ ë…¹ìŒ ì‹œì‘...")
            audio_data = r.listen(source)
            st.write("ğŸ›‘ ë…¹ìŒ ì™„ë£Œ!")
            return audio_data

    # ìƒíƒœ ì´ˆê¸°í™”
    if "recorded" not in st.session_state:
        st.session_state.recorded = False
    if "all_transcripts" not in st.session_state:
        st.session_state.all_transcripts = ""
    if "summaries" not in st.session_state:
        st.session_state.summaries = []

    st.markdown("## 1. ìŒì„± ë…¹ìŒ")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ìŒì„± ë…¹ìŒ ì‹œì‘") and not st.session_state.recorded:
            audio_data = record_audio()

            # ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥
            with open(file_name, "wb") as f:
                f.write(audio_data.get_wav_data())
            
            st.success(f"ë…¹ìŒëœ íŒŒì¼ì´ {file_name}ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state.recorded = True

    with col2:
        if st.button("ì´ˆê¸°í™” í•˜ê¸°"):
            st.session_state.recorded = False
            st.session_state.all_transcripts = ""
            st.session_state.summaries = []
            st.success("ëª¨ë“  ë‚´ìš©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if st.session_state.recorded:
        st.markdown("## 2. ë…¹ìŒ ë‚´ìš© í™•ì¸ ë° ì¶”ê°€")
        # ë…¹ìŒëœ íŒŒì¼ì˜ ê²½ë¡œë¥¼ uploaded_file ë³€ìˆ˜ì— í• ë‹¹
        uploaded_file = file_name

        if uploaded_file is not None:
            user_input = get_audio_input(uploaded_file)
            if user_input is not None:
                st.session_state.all_transcripts += user_input + "\n"
                st.text_area("ëª¨ë“  ë…¹ìŒ ë‚´ìš©:", st.session_state.all_transcripts, height=200)
                
                st.session_state.recorded = False

    st.markdown("## 3. ìš”ì•½í•˜ê¸°")
    if st.button("ìš”ì•½í•˜ê¸°") and st.session_state.all_transcripts:
        load_dotenv()

        meeting_notes = st.session_state.all_transcripts
        prompt = ChatPromptTemplate.from_template("summarize this meeting minutes '{meeting_notes}' in korean")

        model = AzureChatOpenAI(
            azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
            openai_api_version=os.getenv("OPENAI_API_VERSION")
        )
        output_parser = StrOutputParser()

        chain = prompt | model | output_parser

        out = chain.invoke({"meeting_notes": meeting_notes})

        # íšŒì˜ë¡ ìš”ì•½ì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
        st.session_state.summaries.append(out)

        # ëª¨ë“  ìš”ì•½ë³¸ì„ í™”ë©´ì— í‘œì‹œ
        with st.expander("íšŒì˜ë¡ ìš”ì•½"):
            for idx, summary in enumerate(st.session_state.summaries):
                st.text_area(f"íšŒì˜ë¡ ìš”ì•½ {idx + 1}:", summary, height=200)

        # ìµœì¢… ìš”ì•½ë³¸ ìƒì„±
        final_summary = "\n".join(st.session_state.summaries)

        # ìµœì¢… ìš”ì•½ë³¸ì„ í™”ë©´ì— í‘œì‹œ
        st.markdown("## ìµœì¢… ìš”ì•½ë³¸")
        st.text_area("ìµœì¢… ìš”ì•½ë³¸:", final_summary, height=200)

        # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•  ë‚´ìš©
        text_to_save = f"ëª¨ë“  ë…¹ìŒ ë‚´ìš©:\n{st.session_state.all_transcripts}\n\nìµœì¢… ìš”ì•½ë³¸:\n{final_summary}"
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥",
            data=text_to_save,
            file_name="meeting_notes.txt",
            mime="text/plain"
        )

if __name__ == "__main__":
    main()
